library( "MASS" )
library( "loo" )
library( "bayesplot" )
library( "GGally" )
library( "rethinking" )
# Load data
data( "eagles" )
data <- eagles; rm( eagles )
# Set dummy variables
data$P <- ifelse( data$P=="L" , 1 , 0 )
data$A <- ifelse( data$A=="A" , 1 , 0 )
data$V <- ifelse( data$V=="L" , 1 , 0 )
# Create data list for the stan model
data.model <- list(
N = NROW( data ),
y = data$y,
n = data$n,
P = data$P,
A = data$A,
V = data$V
)
str( data.model )
# Model code
model.a.stan <- "
data{
int<lower=1> N;
int y[N];
int n[N];
real P[N];
real A[N];
real V[N];
}
parameters{
real a;
real bP;
real bA;
real bV;
}
model{
vector[N] p;
bV ~ normal( 0 , 5 );
bA ~ normal( 0 , 5 );
bP ~ normal( 0 , 5 );
a ~ normal( 0 , 10 );
for ( i in 1:N ) {
p[i] = a + bP * P[i] + bA * A[i] + bV * V[i];
p[i] = inv_logit(p[i]);
}
y ~ binomial( n , p );
}
generated quantities{
vector[N] log_lik;
vector[N] p;
vector[N] c;
for ( i in 1:N ) {
p[i] = a + bP * P[i] + bA * A[i] + bV * V[i];
p[i] = inv_logit(p[i]);
c[i] = binomial_rng( n[i] , p[i] );
log_lik[i] = binomial_lpmf( y[i] | n[i] , p[i] );
}
}
"
# Fit stan model with model code and model data
fit.a.stan <- stan( model_code=model.a.stan , data=data.model ,
chains=4 , cores=4 , iter=1000 )
# Show results
print( fit.a.stan , probs=c(0.055,0.945) , pars=c("a","bP","bA","bV") )
# Plot coeftab
plot( fit.a.stan , pars=c("a","bP","bA","bV") )
# Paits plot
pairs( fit.a.stan , pars=c("a","bP","bA","bV") )
ggpairs( data=as.data.frame( fit.a.stan ), columns=c(1:4))
# Traceplot
extract_post <- rstan::extract( fit.a.stan , inc_warmup=TRUE , permuted=FALSE)
post_traceplot <- mcmc_trace( extract_post , n_warmup=0 , pars=c("a","bP","bA","bV"),
facet_args=list( nrow=2 , labeller=label_parsed ) )
post_traceplot
# Fit quadratic approximation model
fit.a.quap <- map(
alist(
y ~ dbinom(n, p),
logit(p) <- a + bP*P + bA*A + bV*V,
a ~ dnorm(0, 10),
bP ~ dnorm(0, 5),
bA ~ dnorm(0, 5),
bV ~ dnorm(0, 5)
),
data=data
)
# Show results
precis( fit.a.quap )
# Plot coeftab
plot( coeftab( fit.a.quap ) )
# Pairs plot
pairs( fit.a.quap )
# (b)
# The predicted probability of success and the 89% interval for each row of data is as follows:
print( fit.a.stan , probs=c(0.055,0.945) , pars="p" )
plot( fit.a.stan , pars="p" )
# The predicted success count and the 89% interval for each row of data is as follows:
print( fit.a.stan , probs=c(0.055,0.945) , pars="c" )
plot( fit.a.stan , pars="c" )
# From the results, it shows that the probability of succes could depend on pirate eagle size, victim eagle size and the age of pirate eagle. Besides, the success count is even more relative to the age of pirate eagle.
?coef
# From the results, it shows that the probability of succes could depend on pirate eagle size, victim eagle size and the age of pirate eagle. Besides, the success count is even more relative to the age of pirate eagle.
?coef(fit.a.stan)
# From the results, it shows that the probability of succes could depend on pirate eagle size, victim eagle size and the age of pirate eagle. Besides, the success count is even more relative to the age of pirate eagle.
stats4::coef(fit.a.stan)
# From the results, it shows that the probability of succes could depend on pirate eagle size, victim eagle size and the age of pirate eagle. Besides, the success count is even more relative to the age of pirate eagle.
coef(fit.a.stan)
library( "tidyverse" )
detach_package("tidyverse")
detach("tidyverse")
?detach
detach("tidyverse",unload=true)
library( "dplyr" )
# From the results, it shows that the probability of succes could depend on pirate eagle size, victim eagle size and the age of pirate eagle. Besides, the success count is even more relative to the age of pirate eagle.
post <- as.data.frame(fit.a.stan)
post_cov <- post %>%
select(a, bP, bA, bV) %>%
cov()
post_coef_mean <- post %>%
head() %>%
select(a, bP, bA, bV) %>%
summarise_all(mean) %>%
as.numeric()
post <- MASS::mvrnorm( n=1e4 , mu=coef(m4.1) , Sigma=vcov(m4.1) )
post <- MASS::mvrnorm( n=1e4 , mu=post_cov , Sigma=vcovpost_coef_mean )
# From the results, it shows that the probability of succes could depend on pirate eagle size, victim eagle size and the age of pirate eagle. Besides, the success count is even more relative to the age of pirate eagle.
post <- as.data.frame(fit.a.stan)
post_cov <- post %>%
select(a, bP, bA, bV) %>%
cov()
post_coef_mean <- post %>%
head() %>%
select(a, bP, bA, bV) %>%
summarise_all(mean) %>%
as.numeric()
View(post)
# From the results, it shows that the probability of succes could depend on pirate eagle size, victim eagle size and the age of pirate eagle. Besides, the success count is even more relative to the age of pirate eagle.
str(fit.a.stan)
# From the results, it shows that the probability of succes could depend on pirate eagle size, victim eagle size and the age of pirate eagle. Besides, the success count is even more relative to the age of pirate eagle.
dim(fit.a.stan)
View(fit.a.stan)
# From the results, it shows that the probability of succes could depend on pirate eagle size, victim eagle size and the age of pirate eagle. Besides, the success count is even more relative to the age of pirate eagle.
p <- as.data.frame(fit.a.stan)
View(p)
View(post)
View(p)
# From the results, it shows that the probability of succes could depend on pirate eagle size, victim eagle size and the age of pirate eagle. Besides, the success count is even more relative to the age of pirate eagle.
p <- as.data.frame(fit.a.stan)[13:20,]
p.mean <- apply( p , 2 , mean )
p.PI <- apply( p, 2, PI , prob=0.89 )
# From the results, it shows that the probability of succes could depend on pirate eagle size, victim eagle size and the age of pirate eagle. Besides, the success count is even more relative to the age of pirate eagle.
p <- as.data.frame(fit.a.stan)[13:20,]
p.mean <- apply( p , 2 , mean )
p.PI <- apply( p, 2, PI , prob=0.89 )
c <- as.data.frame(fit.a.stan)[21:28,]
c.mean <- apply( c , 2 , mean )
c.PI <- apply( c, 2, PI , prob=0.89 )
data$success_prob <- data$y / data$n
plot(data$success_prob, col=rangi2, ylab="probability of success", xlab="case", xaxt="n", xlim=c(0.75,8.25) , ylim = c(0, 1), pch=16)
axis(1, at=1:8, labels=c( "LAL","LAS","LIL","LIS","SAL","SAS","SIL","SIS" ))
points( 1:8 , p.mean )
p.mean <- apply( p , 2 , mean )
# From the results, it shows that the probability of succes could depend on pirate eagle size, victim eagle size and the age of pirate eagle. Besides, the success count is even more relative to the age of pirate eagle.
p <- as.data.frame(fit.a.stan)[13:20,]
# From the results, it shows that the probability of succes could depend on pirate eagle size, victim eagle size and the age of pirate eagle. Besides, the success count is even more relative to the age of pirate eagle.
p <- as.data.frame(fit.a.stan)[,13:20]
p.mean <- apply( p , 2 , mean )
p.PI <- apply( p, 2, PI , prob=0.89 )
data$success_prob <- data$y / data$n
plot(data$success_prob, col=rangi2, ylab="probability of success", xlab="case", xaxt="n", xlim=c(0.75,8.25) , ylim = c(0, 1), pch=16)
axis(1, at=1:8, labels=c( "LAL","LAS","LIL","LIS","SAL","SAS","SIL","SIS" ))
points( 1:8 , p.mean )
for ( i in 1:8 ) lines( c(i, i), p.PI[,i] )
c <- as.data.frame(fit.a.stan)[,21:28]
c.mean <- apply( c , 2 , mean )
c.PI <- apply( c, 2, PI , prob=0.89 )
# plot the model predictions for `y` vs. the actual number of successes for each case
plot(d$y, col=rangi2, ylab="number of successes successful", xlab="case", xaxt="n", xlim=c(0.75,8.25) , ylim = c(0, 30), pch=16)
axis(1, at=1:8, labels=c( "LAL","LAS","LIL","LIS","SAL","SAS","SIL","SIS" ))
c <- as.data.frame(fit.a.stan)[,21:28]
c.mean <- apply( c , 2 , mean )
c.PI <- apply( c, 2, PI , prob=0.89 )
# plot the model predictions for `y` vs. the actual number of successes for each case
plot(data$y, col=rangi2, ylab="number of successes successful", xlab="case", xaxt="n", xlim=c(0.75,8.25) , ylim = c(0, 30), pch=16)
axis(1, at=1:8, labels=c( "LAL","LAS","LIL","LIS","SAL","SAS","SIL","SIS" ))
points( 1:8 , c.mean )
for ( i in 1:8 ) lines( c(i, i), c.PI[,i] )
plot(data$success_prob, ylab="probability of success", xlab="case", xaxt="n", xlim=c(0.75,8.25) , ylim = c(0, 1), pch=16)
plot(data$success_prob, col=red, ylab="probability of success", xlab="case", xaxt="n", xlim=c(0.75,8.25) , ylim = c(0, 1), pch=16)
plot(data$success_prob, col=50, ylab="probability of success", xlab="case", xaxt="n", xlim=c(0.75,8.25) , ylim = c(0, 1), pch=16)
plot(data$prob_success, col=50, ylab="probability of success", xlab="each case of data", xaxt="n", xlim=c(0.75,8.25) , ylim = c(0, 1), pch=16)
data$prob_success <- data$y / data$n
plot(data$prob_success, col=50, ylab="probability of success", xlab="each case of data", xaxt="n", xlim=c(0.75,8.25) , ylim = c(0, 1), pch=16)
plot(data$prob_success, col=50, ylab="probability of success", xlab="each case of data", xaxt="n", xlim=c(0.75,8.25) , ylim = c(0, 1))
plot(data$prob_success, col=50, ylab="probability of success", xlab="each case of data", xaxt="n", xlim=c(0.75,8.25) , ylim=c(0, 1) , pch=30 )
plot(data$prob_success, col=50, ylab="probability of success", xlab="each case of data", xaxt="n", xlim=c(0.75,8.25) , ylim=c(0, 1) , pch=16 )
plot(data$prob_success, col=50, ylab="probability of success", xlab="each case of data", xlim=c(0,9) , ylim=c(0,1) , pch=16 )
xaxt="n",
plot(data$prob_success, col=50, ylab="probability of success", xlab="each case of data", xaxt="n", xlim=c(0,9) , ylim=c(0,1) , pch=16 )
plot(data$prob_success, col=50, ylab="probability of success", xlab="each case of data", xlim=c(0,9) , ylim=c(0,1) , pch=16 , xaxt="n" )
axis(1, at=1:8, labels=c( "LAL","LAS","LIL","LIS","SAL","SAS","SIL","SIS" ))
points( 1:8 , p.mean )
for ( i in 1:8 ) lines( c(i, i), p.PI[,i] )
plot( data$y , col=50 , ylab="count of success" , xlab="each case of data" , xlim=c(0,9) , ylim=c(0,30) , pch=16 , xaxt="n" )
c <- as.data.frame(fit.a.stan)[,21:28]
c.mean <- apply( c , 2 , mean )
c.PI <- apply( c, 2, PI , prob=0.89 )
plot( data$y , col=50 , ylab="count of success" , xlab="each case of data" , xlim=c(0,9) , ylim=c(0,30) , pch=16 , xaxt="n" )
axis( 1 , at=1:8 , labels=c("LAL","LAS","LIL","LIS","SAL","SAS","SIL","SIS") )
View(data)
p <- as.data.frame(fit.a.stan)[,13:20]
p.mean <- apply( p , 2 , mean )
p.PI <- apply( p, 2, PI , prob=0.89 )
data$prob_success <- data$y / data$n
plot( data$prob_success , col=50 , ylab="probability of success" , xlab="each case of data (P.A.V)" , xlim=c(0,9) , ylim=c(0,1) , pch=16 , xaxt="n" )
axis( 1 , at=1:8 , labels=c("L.A.L","L.A.S","L.I.L","L.I.S","S.A.L","S.A.S","S.I.L","S.I.S") )
points( 1:8 , p.mean )
for ( i in 1:8 ) lines( c(i, i), p.PI[,i] )
c <- as.data.frame(fit.a.stan)[,21:28]
c.mean <- apply( c , 2 , mean )
c.PI <- apply( c, 2, PI , prob=0.89 )
plot( data$y , col=50 , ylab="count of success" , xlab="each case of data (P.A.V)" , xlim=c(0,9) , ylim=c(0,30) , pch=16 , xaxt="n" )
axis( 1 , at=1:8 , labels=c("L.A.L","L.A.S","L.I.L","L.I.S","S.A.L","S.A.S","S.I.L","S.I.S") )
points( 1:8 , c.mean )
for ( i in 1:8 ) lines( c(i, i), c.PI[,i] )
# (c)
model.c.stan <- "
data{
int<lower=1> N;
int y[N];
int n[N];
real P[N];
real A[N];
real V[N];
}
parameters{
real a;
real bP;
real bA;
real bV;
real bPA;
}
model{
vector[N] p;
bPA ~ normal( 0 , 5 );
bV ~ normal( 0 , 5 );
bA ~ normal( 0 , 5 );
bP ~ normal( 0 , 5 );
a ~ normal( 0 , 10 );
for ( i in 1:N ) {
p[i] = a + bP * P[i] + bA * A[i] + bV * V[i] + bPA * P[i] * A[i];
p[i] = inv_logit(p[i]);
}
y ~ binomial( n , p );
}
generated quantities{
vector[N] log_lik;
vector[N] p;
for ( i in 1:N ) {
p[i] = a + bP * P[i] + bA * A[i] + bV * V[i] + bPA * P[i] * A[i];
p[i] = inv_logit(p[i]);
log_lik[i] = binomial_lpmf( y[i] | n[i] , p[i] );
}
}
"
library( "MASS" )
library( "dplyr" )
library( "loo" )
library( "bayesplot" )
library( "rethinking" )
library( "GGally" )
?mcmc_trace
